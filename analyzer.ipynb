{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk4vq90lkZxy"
      },
      "source": [
        "First, let's import the required libraries and packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 419,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1lLm-wwSdKc",
        "outputId": "1c6bb3c2-6499-4c71-c9cd-28669f656529"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/rizkyario/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /Users/rizkyario/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/rizkyario/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Error loading : Package '' not found in index\n",
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /Users/rizkyario/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     /Users/rizkyario/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: pyLDAvis==2.1.2 in /usr/local/lib/python3.7/site-packages (2.1.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/site-packages (from pyLDAvis==2.1.2) (7.1.2)\n",
            "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.7/site-packages (from pyLDAvis==2.1.2) (0.37.1)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.7/site-packages (from pyLDAvis==2.1.2) (3.0.3)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/site-packages (from pyLDAvis==2.1.2) (1.17)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.7/site-packages (from pyLDAvis==2.1.2) (1.3.5)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.7/site-packages (from pyLDAvis==2.1.2) (1.1.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/site-packages (from pyLDAvis==2.1.2) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/site-packages (from pyLDAvis==2.1.2) (1.21.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/site-packages (from pyLDAvis==2.1.2) (0.18.2)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.7/site-packages (from pyLDAvis==2.1.2) (1.7.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/site-packages (from jinja2>=2.7.2->pyLDAvis==2.1.2) (2.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas>=0.17.0->pyLDAvis==2.1.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/site-packages (from pandas>=0.17.0->pyLDAvis==2.1.2) (2020.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/site-packages (from numexpr->pyLDAvis==2.1.2) (21.3)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/site-packages (from pytest->pyLDAvis==2.1.2) (21.4.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.7/site-packages (from pytest->pyLDAvis==2.1.2) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/site-packages (from pytest->pyLDAvis==2.1.2) (3.4.0)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/site-packages (from pytest->pyLDAvis==2.1.2) (1.11.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/site-packages (from pytest->pyLDAvis==2.1.2) (1.1.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/site-packages (from pytest->pyLDAvis==2.1.2) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->pyLDAvis==2.1.2) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->pyLDAvis==2.1.2) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=0.17.0->pyLDAvis==2.1.2) (1.12.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/site-packages (from packaging->numexpr->pyLDAvis==2.1.2) (3.0.7)\n",
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import os\n",
        "\n",
        "#ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#import json to view the json data provided\n",
        "import json\n",
        "\n",
        "#basic data analysis libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "#visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import plotly.express as px\n",
        "\n",
        "#Text Libraries\n",
        "\n",
        "#NLTK\n",
        "#!pip install nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "#String\n",
        "import string\n",
        "from textblob import TextBlob\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "#sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "#Gensim\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "!pip install pyLDAvis==2.1.2\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME4ngU0nkhZ8"
      },
      "source": [
        "Opening the JSON file using the json library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 420,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORSsSEr9S5Hs",
        "outputId": "81c230fc-c4d0-4eac-8652-ac580384b4d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1440\n"
          ]
        }
      ],
      "source": [
        "# Opening the JSON file\n",
        "json_dir = './data/vestiairecollective'\n",
        "\n",
        "json_pattern = os.path.join(json_dir, '*.json')\n",
        "file_list = glob.glob(json_pattern)\n",
        "\n",
        "dfs = []\n",
        "for file in file_list:\n",
        "    with open(file) as f:\n",
        "        json_data = pd.json_normalize(json.loads(f.read()))\n",
        "        json_data['site'] = file.rsplit(\"/\", 1)[-1]\n",
        "    dfs.append(json_data)\n",
        "df = pd.concat(dfs)\n",
        "print(len(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HtaQ8q7knXe"
      },
      "source": [
        "Opening the JSON data using Pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 421,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "o5Dar_QNTFC1",
        "outputId": "f9186e47-52da-43f0-dc0d-6172d3ceb69f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "      <th>stars</th>\n",
              "      <th>location</th>\n",
              "      <th>url</th>\n",
              "      <th>site</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-05-05</td>\n",
              "      <td>Savinee</td>\n",
              "      <td>Worst customer service! \\nI sold my Dior bag w...</td>\n",
              "      <td>Sold £1,000 bag but not paid by VC</td>\n",
              "      <td>1</td>\n",
              "      <td>GB</td>\n",
              "      <td>https://www.trustpilot.com/review/vestiairecol...</td>\n",
              "      <td>reviews_15.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-05-05</td>\n",
              "      <td>Fanny Ann</td>\n",
              "      <td>THEY THINK THEY CAN IGNORE FOWL TREATMENT BY C...</td>\n",
              "      <td>THEY THINK THEY CAN IGNORE FOWL…</td>\n",
              "      <td>1</td>\n",
              "      <td>GB</td>\n",
              "      <td>https://www.trustpilot.com/review/vestiairecol...</td>\n",
              "      <td>reviews_15.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-05-05</td>\n",
              "      <td>David</td>\n",
              "      <td>RE: Louis Vuitton leather backpack - item: 223...</td>\n",
              "      <td>RE: REFUND</td>\n",
              "      <td>1</td>\n",
              "      <td>SA</td>\n",
              "      <td>https://www.trustpilot.com/review/vestiairecol...</td>\n",
              "      <td>reviews_15.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-05-05</td>\n",
              "      <td>Jess Palmer</td>\n",
              "      <td>Messed up my expert badge  and shadow banned i...</td>\n",
              "      <td>Messed up my expert badge, my account  and sha...</td>\n",
              "      <td>1</td>\n",
              "      <td>GB</td>\n",
              "      <td>https://www.trustpilot.com/review/vestiairecol...</td>\n",
              "      <td>reviews_15.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-05-06</td>\n",
              "      <td>shay</td>\n",
              "      <td>I sold an authentic LV belt on this platform 2...</td>\n",
              "      <td>Loss of money and my item...</td>\n",
              "      <td>1</td>\n",
              "      <td>GB</td>\n",
              "      <td>https://www.trustpilot.com/review/vestiairecol...</td>\n",
              "      <td>reviews_15.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2022-05-06</td>\n",
              "      <td>Fumming</td>\n",
              "      <td>Ignorant \\nUnresponsive \\nTreat seller appalli...</td>\n",
              "      <td>Ignorant</td>\n",
              "      <td>1</td>\n",
              "      <td>GB</td>\n",
              "      <td>https://www.trustpilot.com/review/vestiairecol...</td>\n",
              "      <td>reviews_15.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2022-05-06</td>\n",
              "      <td>Jessica Greenslade</td>\n",
              "      <td>Order placed for a pair of shoes in a UK 6.5, ...</td>\n",
              "      <td>Scammers</td>\n",
              "      <td>1</td>\n",
              "      <td>GB</td>\n",
              "      <td>https://www.trustpilot.com/review/vestiairecol...</td>\n",
              "      <td>reviews_15.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2022-05-06</td>\n",
              "      <td>Mouj</td>\n",
              "      <td>I sold a Fendi bag with them, and my buyer has...</td>\n",
              "      <td>Terribe, DO NOT USE THEM</td>\n",
              "      <td>1</td>\n",
              "      <td>CA</td>\n",
              "      <td>https://www.trustpilot.com/review/vestiairecol...</td>\n",
              "      <td>reviews_15.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2022-05-06</td>\n",
              "      <td>Claire</td>\n",
              "      <td>I was excited to order a vintage mulberry hand...</td>\n",
              "      <td>Counterfeit goods knowingly sold</td>\n",
              "      <td>1</td>\n",
              "      <td>GB</td>\n",
              "      <td>https://www.trustpilot.com/review/vestiairecol...</td>\n",
              "      <td>reviews_15.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2022-05-06</td>\n",
              "      <td>Mas</td>\n",
              "      <td>I have bought from Vestiaire a few times now. ...</td>\n",
              "      <td>BEWARE of FAKES! Authenticity checks are terri...</td>\n",
              "      <td>1</td>\n",
              "      <td>SG</td>\n",
              "      <td>https://www.trustpilot.com/review/vestiairecol...</td>\n",
              "      <td>reviews_15.json</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date              author  \\\n",
              "0  2022-05-05             Savinee   \n",
              "1  2022-05-05           Fanny Ann   \n",
              "2  2022-05-05               David   \n",
              "3  2022-05-05         Jess Palmer   \n",
              "4  2022-05-06                shay   \n",
              "5  2022-05-06             Fumming   \n",
              "6  2022-05-06  Jessica Greenslade   \n",
              "7  2022-05-06                Mouj   \n",
              "8  2022-05-06              Claire   \n",
              "9  2022-05-06                 Mas   \n",
              "\n",
              "                                                text  \\\n",
              "0  Worst customer service! \\nI sold my Dior bag w...   \n",
              "1  THEY THINK THEY CAN IGNORE FOWL TREATMENT BY C...   \n",
              "2  RE: Louis Vuitton leather backpack - item: 223...   \n",
              "3  Messed up my expert badge  and shadow banned i...   \n",
              "4  I sold an authentic LV belt on this platform 2...   \n",
              "5  Ignorant \\nUnresponsive \\nTreat seller appalli...   \n",
              "6  Order placed for a pair of shoes in a UK 6.5, ...   \n",
              "7  I sold a Fendi bag with them, and my buyer has...   \n",
              "8  I was excited to order a vintage mulberry hand...   \n",
              "9  I have bought from Vestiaire a few times now. ...   \n",
              "\n",
              "                                               title  stars location  \\\n",
              "0                 Sold £1,000 bag but not paid by VC      1       GB   \n",
              "1                   THEY THINK THEY CAN IGNORE FOWL…      1       GB   \n",
              "2                                         RE: REFUND      1       SA   \n",
              "3  Messed up my expert badge, my account  and sha...      1       GB   \n",
              "4                       Loss of money and my item...      1       GB   \n",
              "5                                           Ignorant      1       GB   \n",
              "6                                           Scammers      1       GB   \n",
              "7                           Terribe, DO NOT USE THEM      1       CA   \n",
              "8                   Counterfeit goods knowingly sold      1       GB   \n",
              "9  BEWARE of FAKES! Authenticity checks are terri...      1       SG   \n",
              "\n",
              "                                                 url             site  \n",
              "0  https://www.trustpilot.com/review/vestiairecol...  reviews_15.json  \n",
              "1  https://www.trustpilot.com/review/vestiairecol...  reviews_15.json  \n",
              "2  https://www.trustpilot.com/review/vestiairecol...  reviews_15.json  \n",
              "3  https://www.trustpilot.com/review/vestiairecol...  reviews_15.json  \n",
              "4  https://www.trustpilot.com/review/vestiairecol...  reviews_15.json  \n",
              "5  https://www.trustpilot.com/review/vestiairecol...  reviews_15.json  \n",
              "6  https://www.trustpilot.com/review/vestiairecol...  reviews_15.json  \n",
              "7  https://www.trustpilot.com/review/vestiairecol...  reviews_15.json  \n",
              "8  https://www.trustpilot.com/review/vestiairecol...  reviews_15.json  \n",
              "9  https://www.trustpilot.com/review/vestiairecol...  reviews_15.json  "
            ]
          },
          "execution_count": 421,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Using Pandas\n",
        "\n",
        "json_pattern = os.path.join(json_dir, '*.json')\n",
        "file_list = glob.glob(json_pattern)\n",
        "\n",
        "dfs = []\n",
        "for file in file_list:\n",
        "    with open(file) as f:\n",
        "        json_data = pd.json_normalize(json.loads(f.read()))\n",
        "        json_data['site'] = file.rsplit(\"/\", 1)[-1]\n",
        "    dfs.append(json_data)\n",
        "reviewsDF = pd.concat(dfs)\n",
        "reviewsDF.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX3hyb7xcjWJ"
      },
      "source": [
        "# **Data Cleaning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF1aIL1UkugH"
      },
      "source": [
        "Round 1 of cleaning: \n",
        "\n",
        "- Converting the text to Lowercase\n",
        "\n",
        "- Removing text in brackets\n",
        "\n",
        "- Removing punctuation and words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 422,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0m9rcjvTHvZ",
        "outputId": "40ccd2fc-1652-4636-f288-bdebeaa9baa7"
      },
      "outputs": [],
      "source": [
        "#Round 1 of cleaning\n",
        "def clean_text(text):\n",
        "    # converting to lower\n",
        "    text = text.lower() \n",
        "    #remove text in square brackets\n",
        "    text = re.sub('\\[.*?\\]','',text)\n",
        "    #remove punctuation and remove words\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation),'',text)\n",
        "    text = re.sub('\\w*\\d\\w*','',text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 423,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "v8j9Kuiad4iX",
        "outputId": "b301b261-adbb-424c-e2ba-f1fafb780b54"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "      <th>stars</th>\n",
              "      <th>location</th>\n",
              "      <th>url</th>\n",
              "      <th>site</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-05-05</td>\n",
              "      <td>Savinee</td>\n",
              "      <td>worst customer service \\ni sold my dior bag wo...</td>\n",
              "      <td>sold £ bag but not paid by vc</td>\n",
              "      <td>1</td>\n",
              "      <td>GB</td>\n",
              "      <td>https://www.trustpilot.com/review/vestiairecol...</td>\n",
              "      <td>reviews_15.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-05-05</td>\n",
              "      <td>Fanny Ann</td>\n",
              "      <td>they think they can ignore fowl treatment by c...</td>\n",
              "      <td>they think they can ignore fowl…</td>\n",
              "      <td>1</td>\n",
              "      <td>GB</td>\n",
              "      <td>https://www.trustpilot.com/review/vestiairecol...</td>\n",
              "      <td>reviews_15.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-05-05</td>\n",
              "      <td>David</td>\n",
              "      <td>re louis vuitton leather backpack  item \\n\\npu...</td>\n",
              "      <td>re refund</td>\n",
              "      <td>1</td>\n",
              "      <td>SA</td>\n",
              "      <td>https://www.trustpilot.com/review/vestiairecol...</td>\n",
              "      <td>reviews_15.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-05-05</td>\n",
              "      <td>Jess Palmer</td>\n",
              "      <td>messed up my expert badge  and shadow banned i...</td>\n",
              "      <td>messed up my expert badge my account  and shadow…</td>\n",
              "      <td>1</td>\n",
              "      <td>GB</td>\n",
              "      <td>https://www.trustpilot.com/review/vestiairecol...</td>\n",
              "      <td>reviews_15.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-05-06</td>\n",
              "      <td>shay</td>\n",
              "      <td>i sold an authentic lv belt on this platform  ...</td>\n",
              "      <td>loss of money and my item</td>\n",
              "      <td>1</td>\n",
              "      <td>GB</td>\n",
              "      <td>https://www.trustpilot.com/review/vestiairecol...</td>\n",
              "      <td>reviews_15.json</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date       author                                               text  \\\n",
              "0  2022-05-05      Savinee  worst customer service \\ni sold my dior bag wo...   \n",
              "1  2022-05-05    Fanny Ann  they think they can ignore fowl treatment by c...   \n",
              "2  2022-05-05        David  re louis vuitton leather backpack  item \\n\\npu...   \n",
              "3  2022-05-05  Jess Palmer  messed up my expert badge  and shadow banned i...   \n",
              "4  2022-05-06         shay  i sold an authentic lv belt on this platform  ...   \n",
              "\n",
              "                                               title  stars location  \\\n",
              "0                      sold £ bag but not paid by vc      1       GB   \n",
              "1                   they think they can ignore fowl…      1       GB   \n",
              "2                                          re refund      1       SA   \n",
              "3  messed up my expert badge my account  and shadow…      1       GB   \n",
              "4                          loss of money and my item      1       GB   \n",
              "\n",
              "                                                 url             site  \n",
              "0  https://www.trustpilot.com/review/vestiairecol...  reviews_15.json  \n",
              "1  https://www.trustpilot.com/review/vestiairecol...  reviews_15.json  \n",
              "2  https://www.trustpilot.com/review/vestiairecol...  reviews_15.json  \n",
              "3  https://www.trustpilot.com/review/vestiairecol...  reviews_15.json  \n",
              "4  https://www.trustpilot.com/review/vestiairecol...  reviews_15.json  "
            ]
          },
          "execution_count": 423,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviewsDF.title = reviewsDF.title.apply(clean_text)\n",
        "reviewsDF.text = reviewsDF.text.apply(clean_text)\n",
        "reviewsDF.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLb4LNtblAPn"
      },
      "source": [
        "Round 2 of Cleaning:\n",
        "\n",
        "- Removing additional punctuation\n",
        "\n",
        "- Removing non-sensical text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 424,
      "metadata": {
        "id": "L2zh5PolXb3t"
      },
      "outputs": [],
      "source": [
        "#Round 2 of cleaning\n",
        "def clean_text2(text):\n",
        "    '''get rid of some additional punctuation and non-sesical text that was missed the first time'''\n",
        "    text = re.sub('[''\"\"...]','',text)\n",
        "    text = re.sub('\\n','',text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 425,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "R5HMyh6IebeI",
        "outputId": "a19865c5-bf0e-4400-9a08-af0061e638e0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "      <th>stars</th>\n",
              "      <th>location</th>\n",
              "      <th>url</th>\n",
              "      <th>site</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-05-05</td>\n",
              "      <td>Savinee</td>\n",
              "      <td>worst customer service i sold my dior bag wort...</td>\n",
              "      <td>sold £ bag but not paid by vc</td>\n",
              "      <td>1</td>\n",
              "      <td>GB</td>\n",
              "      <td>https://www.trustpilot.com/review/vestiairecol...</td>\n",
              "      <td>reviews_15.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-05-05</td>\n",
              "      <td>Fanny Ann</td>\n",
              "      <td>they think they can ignore fowl treatment by c...</td>\n",
              "      <td>they think they can ignore fowl…</td>\n",
              "      <td>1</td>\n",
              "      <td>GB</td>\n",
              "      <td>https://www.trustpilot.com/review/vestiairecol...</td>\n",
              "      <td>reviews_15.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-05-05</td>\n",
              "      <td>David</td>\n",
              "      <td>re louis vuitton leather backpack  item purcha...</td>\n",
              "      <td>re refund</td>\n",
              "      <td>1</td>\n",
              "      <td>SA</td>\n",
              "      <td>https://www.trustpilot.com/review/vestiairecol...</td>\n",
              "      <td>reviews_15.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-05-05</td>\n",
              "      <td>Jess Palmer</td>\n",
              "      <td>messed up my expert badge  and shadow banned i...</td>\n",
              "      <td>messed up my expert badge my account  and shadow…</td>\n",
              "      <td>1</td>\n",
              "      <td>GB</td>\n",
              "      <td>https://www.trustpilot.com/review/vestiairecol...</td>\n",
              "      <td>reviews_15.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-05-06</td>\n",
              "      <td>shay</td>\n",
              "      <td>i sold an authentic lv belt on this platform  ...</td>\n",
              "      <td>loss of money and my item</td>\n",
              "      <td>1</td>\n",
              "      <td>GB</td>\n",
              "      <td>https://www.trustpilot.com/review/vestiairecol...</td>\n",
              "      <td>reviews_15.json</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date       author                                               text  \\\n",
              "0  2022-05-05      Savinee  worst customer service i sold my dior bag wort...   \n",
              "1  2022-05-05    Fanny Ann  they think they can ignore fowl treatment by c...   \n",
              "2  2022-05-05        David  re louis vuitton leather backpack  item purcha...   \n",
              "3  2022-05-05  Jess Palmer  messed up my expert badge  and shadow banned i...   \n",
              "4  2022-05-06         shay  i sold an authentic lv belt on this platform  ...   \n",
              "\n",
              "                                               title  stars location  \\\n",
              "0                      sold £ bag but not paid by vc      1       GB   \n",
              "1                   they think they can ignore fowl…      1       GB   \n",
              "2                                          re refund      1       SA   \n",
              "3  messed up my expert badge my account  and shadow…      1       GB   \n",
              "4                          loss of money and my item      1       GB   \n",
              "\n",
              "                                                 url             site  \n",
              "0  https://www.trustpilot.com/review/vestiairecol...  reviews_15.json  \n",
              "1  https://www.trustpilot.com/review/vestiairecol...  reviews_15.json  \n",
              "2  https://www.trustpilot.com/review/vestiairecol...  reviews_15.json  \n",
              "3  https://www.trustpilot.com/review/vestiairecol...  reviews_15.json  \n",
              "4  https://www.trustpilot.com/review/vestiairecol...  reviews_15.json  "
            ]
          },
          "execution_count": 425,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviewsDF.title = reviewsDF.title.apply(clean_text2)\n",
        "reviewsDF.text = reviewsDF.text.apply(clean_text2)\n",
        "reviewsDF.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sZbppKdlNkN"
      },
      "source": [
        "Round 3 of Cleaning:\n",
        "\n",
        "- Punctuation\n",
        "\n",
        "- Words containing numbers\n",
        "\n",
        "- Stopwords\n",
        "\n",
        "- Empty tokens\n",
        "\n",
        "- Part of Speech Tagging\n",
        "\n",
        "- Lemmatization\n",
        "\n",
        "- Removing one letter words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 426,
      "metadata": {
        "id": "md55n-E9eeVy"
      },
      "outputs": [],
      "source": [
        "#Round 3 of cleaning (postag, stopwords removal and lemmatization etc)\n",
        "def get_wordnet_pos(word):\n",
        "    #Map POS tag to first letter\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "    \n",
        "def clean_text3(text):\n",
        "    #tokenizing removing puncutation\n",
        "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
        "    #removing words containing numbers\n",
        "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
        "    #removing stopwords\n",
        "    stop = stopwords.words('english')\n",
        "    text = [x for x in text if x not in stop]\n",
        "    #removing empty tokens\n",
        "    text = [t for t in text if len(t) > 0]\n",
        "    #part of speech tagging\n",
        "    pos_tags = pos_tag(text)\n",
        "    #lemmatizing text\n",
        "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
        "    #removing one letter words\n",
        "    text = [t for t in text if len(t) > 1]\n",
        "    #joining\n",
        "    text = \" \".join(text)\n",
        "    return(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 427,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "lOXSK7xsgDXO",
        "outputId": "00193a00-4550-49d0-d442-29d912fea499"
      },
      "outputs": [],
      "source": [
        "reviewsDF.title = reviewsDF.title.apply(clean_text3)\n",
        "reviewsDF.text = reviewsDF.text.apply(clean_text3)\n",
        "reviewsDF.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO36eM80li9D"
      },
      "source": [
        "Save the Cleaned data for easy later use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhsZv44hgHNW"
      },
      "outputs": [],
      "source": [
        "reviewsDF = reviewsDF.drop_duplicates(subset='text', keep=\"last\")\n",
        "\n",
        "#Pickling the DF for later use\n",
        "reviewsDF.to_pickle(\"corpus.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ5D-Eu8miWb"
      },
      "source": [
        "# **Feature Engineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnhUZxiXlqgt"
      },
      "source": [
        "Adding new columns for\n",
        "1. Length\n",
        "2. Word Count\n",
        "3. Polarity\n",
        "4. Sentiment\n",
        "5. Rating\n",
        "6. Website"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "63LvF1nplGx-",
        "outputId": "df4935c7-d596-4ea3-c3d3-4ed8cdf5a504"
      },
      "outputs": [],
      "source": [
        "#Let's add a column length, which indicates the length of each text\n",
        "reviewsDF['length'] = reviewsDF['text'].apply(len)\n",
        "#Adding a column numOfWords which indicates the number of words in the text\n",
        "reviewsDF['numOfWords'] = reviewsDF['text'].apply(lambda x: len(x.split(\" \")))\n",
        "#Adding a Polarity column - using TextBlob\n",
        "reviewsDF['polarity'] = reviewsDF['text'].map(lambda text: TextBlob(text).sentiment.polarity)\n",
        "#Adding Sentiment Intensity column - using SentimentIntensityAnalyzer\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "reviewsDF[\"sentiments\"] = reviewsDF[\"text\"].apply(lambda x: sid.polarity_scores(x))\n",
        "reviewsDF = pd.concat([reviewsDF.drop(['sentiments'], axis=1), reviewsDF['sentiments'].apply(pd.Series)], axis=1)\n",
        "reviewsDF.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwUXwpKVpXT-",
        "outputId": "68479112-bba2-48f5-ced7-a7d08af8fc73"
      },
      "outputs": [],
      "source": [
        "#Adding a Sentiment column depending on the calculated compound score\n",
        "reviewsDF['Sentiment'] = reviewsDF['compound'].apply(lambda c: 'pos' if c >=0 else 'neg')\n",
        "reviewsDF.Sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "tB5P5OzYpDkR",
        "outputId": "9f7e66e5-a45e-4699-84cd-007f072c4843"
      },
      "outputs": [],
      "source": [
        "#Adding a column (numeric) for rating\n",
        "#reviewsDF.stars.value_counts()\n",
        "reviewsDF['rating'] = reviewsDF['stars']\n",
        "reviewsDF.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "K-TWCtGUrw8x",
        "outputId": "154260c0-ed78-4289-de75-076cb7b05c03"
      },
      "outputs": [],
      "source": [
        "#Analyzing URL column\n",
        "reviewsDF.url.str.split(\"review/\")[0]\n",
        "reviewsDF['Site'] = reviewsDF.url.apply(lambda x: x.split(\"review/\")[1])\n",
        "reviewsDF.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDH8mGk-sjv8",
        "outputId": "e354dd84-bd65-46e6-e3a3-e399b7018e1d"
      },
      "outputs": [],
      "source": [
        "reviewsDF.Site.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6oZE5MJq4Ih"
      },
      "source": [
        "# **EDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBf1i_cOmBEe"
      },
      "source": [
        "Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "OSJ1sXx4q_7r",
        "outputId": "3e7e0759-bca9-40cb-9d1d-e75ec3b6733a"
      },
      "outputs": [],
      "source": [
        "#This function is used to see mathematical metrics of all the columns \n",
        "reviewsDF.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3WMEb7Is8i9",
        "outputId": "b94260aa-e80b-4ab6-a36c-522754a40851"
      },
      "outputs": [],
      "source": [
        "#To see the type of each column and check if there are any null values \n",
        "reviewsDF.date = pd.to_datetime(reviewsDF['date'])\n",
        "\n",
        "reviewsDF.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bt-T53PztDZg",
        "outputId": "3e0695e1-ee99-4f45-ac2d-8d1c8c4bdc98"
      },
      "outputs": [],
      "source": [
        "#To count number of samples for each rating\n",
        "reviewsDF.rating.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "1LWEIeLRtKOj",
        "outputId": "b694641a-820b-492b-c0b9-29872f7dfafd"
      },
      "outputs": [],
      "source": [
        "# Review length distribution\n",
        "reviewsDF['length'].hist(bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "UR3LTyvXuQyS",
        "outputId": "a3dd65bb-b20d-486d-a4fb-17aca78063e2"
      },
      "outputs": [],
      "source": [
        "#Histogram plot to see the lenght of each rating\n",
        "reviewsDF.hist(column = 'length', by = 'rating')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "6atIkPLNtsBZ",
        "outputId": "3dc40a65-20b3-4f2a-a17b-408fc1e91f80"
      },
      "outputs": [],
      "source": [
        "#Histogram plot to analyze number of reviews with respect to date\n",
        "#As we can see, 2018 has many reviews comapared to other years\n",
        "fig = px.histogram(reviewsDF, x='date', title='Reviews by date')\n",
        "fig.update_xaxes(categoryorder='category descending', title='Date').update_yaxes(title='Number of reviews')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "ssApK2rktwPN",
        "outputId": "eeb1a908-8395-47b2-df07-2bbeaef00ddb"
      },
      "outputs": [],
      "source": [
        "#Histogram plot to analyze number of reviews with respect to date and ratings\n",
        "#As we can see there are many one star ratings compared to all other ratings \n",
        "fig = px.histogram(reviewsDF, x='date',  title='Reviews by date', color='rating', nbins=10, log_y=True, barmode='group')\n",
        "fig.update_xaxes(categoryorder='category descending', title='Date').update_yaxes(title='Number of reviews')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "o_Z2mdiLt6WK",
        "outputId": "9aba273e-c4ee-4536-aa3c-20d17a74ba5d"
      },
      "outputs": [],
      "source": [
        "#Histogram plot for polarity, and by observing we say that there are many reviwes with the polarity between 0 to 0.25\n",
        "reviewsDF.polarity.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "X2w4MIlmuND1",
        "outputId": "537fcd1e-2283-4815-9781-a93db42f5069"
      },
      "outputs": [],
      "source": [
        "#Plot to analyze number of words\n",
        "reviewsDF['numOfWords'].hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "KWiivDUgyzAD",
        "outputId": "f7f9d72f-2e99-4c86-c63a-6552a8cdaf1a"
      },
      "outputs": [],
      "source": [
        "#top positive reviews\n",
        "reviewsDF.sort_values(\"pos\", ascending = False)[[\"text\", \"pos\", \"neg\"]].head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "6bRQ94ZAzA42",
        "outputId": "9425fe80-e4e1-4a84-df7a-25c596051f9a"
      },
      "outputs": [],
      "source": [
        "#Analyzing the negative data - ascending order \n",
        "reviewsDF.sort_values(\"neg\", ascending = False)[[\"text\", \"pos\", \"neg\"]].head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xihTuYDNzG6t",
        "outputId": "11e0ec0c-04b4-468f-d0b8-36394d5a9183"
      },
      "outputs": [],
      "source": [
        "# reviewsDF['length'][1234]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "FSYI_s2euYaz",
        "outputId": "264ec557-4bfa-4a2a-9651-2140a9120ab1"
      },
      "outputs": [],
      "source": [
        "#WordCloud of text in the complete data set\n",
        "wordcloud = WordCloud(max_words = 200, max_font_size = 40, scale = 3, random_state = 42).generate(str(reviewsDF['text']))\n",
        "fig = plt.figure(1, figsize = (20, 20))\n",
        "plt.axis('off')\n",
        "plt.imshow(wordcloud)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuyWNAsGwSil",
        "outputId": "5058433e-ec32-4b31-d770-2b926afda39b"
      },
      "outputs": [],
      "source": [
        "#Percentage of each word in the wordcloud\n",
        "wordcloud.words_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFSH1O7Zw7jV"
      },
      "source": [
        "# **Topic Modelling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1R6VR2lwkdO"
      },
      "outputs": [],
      "source": [
        "reviewData = reviewsDF['text']\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', use_idf=True, smooth_idf=True)\n",
        "reviewData = reviewData.values\n",
        "document_term_matrix = tfidf_vectorizer.fit_transform(reviewData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N477nraHxUyd"
      },
      "outputs": [],
      "source": [
        "#Let's consider the top 20 topics\n",
        "n_topics = 10\n",
        "lsa_model = TruncatedSVD(n_components=n_topics)\n",
        "lsa_topic_matrix = lsa_model.fit_transform(document_term_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1ViOcYqxcaP"
      },
      "outputs": [],
      "source": [
        "def getCategoriesCounts(lsa_topic_matrix):\n",
        "  keys = lsa_topic_matrix.argmax(axis=1).tolist()\n",
        "  count_pairs = Counter(keys).items()\n",
        "  categories = [pair[0] for pair in count_pairs]\n",
        "  counts = [pair[1] for pair in count_pairs]\n",
        "  return (keys,categories, counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNwJE5oPx4xJ"
      },
      "outputs": [],
      "source": [
        "lsa_keys, lsa_categories, lsa_counts = getCategoriesCounts(lsa_topic_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZYpai5Sx8ou"
      },
      "outputs": [],
      "source": [
        "def get_top_n_words(n, keys, document_term_matrix, tfidf_vectorizer):\n",
        "    top_indices = []\n",
        "    for topic in range(n_topics):\n",
        "        temp_vector_sum = 0\n",
        "        for i in range(len(keys)):\n",
        "            if keys[i] == topic:\n",
        "                temp_vector_sum += document_term_matrix[i]\n",
        "        temp_vector_sum = temp_vector_sum.toarray()\n",
        "        top_n_word_indices = np.flip(np.argsort(temp_vector_sum)[0][-n:],0)\n",
        "        top_indices.append(top_n_word_indices)   \n",
        "    top_words = []\n",
        "    for topic in top_indices:\n",
        "        topic_words = []\n",
        "        for index in topic:\n",
        "            temp_word_vector = np.zeros((1,document_term_matrix.shape[1]))\n",
        "            temp_word_vector[:,index] = 1\n",
        "            the_word = tfidf_vectorizer.inverse_transform(temp_word_vector)[0][0]\n",
        "            topic_words.append(the_word.encode('ascii').decode('utf-8'))\n",
        "        top_words.append(\" \".join(topic_words))         \n",
        "    return top_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcWeiReByPQ0",
        "outputId": "3b365370-c6b8-4714-b652-21e3318fb32a"
      },
      "outputs": [],
      "source": [
        "top_n_words_lsa = get_top_n_words(3, lsa_keys, document_term_matrix, tfidf_vectorizer)\n",
        "for i in range(len(top_n_words_lsa)):\n",
        "    print(\"Topic {}: \".format(i+1), top_n_words_lsa[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BqEQDkjLo51"
      },
      "source": [
        "We can see the top 20 topics in the whole dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfnTQo6vmKe5"
      },
      "source": [
        "Now let's compare the topics year by year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyLULNT43Gsu",
        "outputId": "cd8677f4-bfcd-4925-983e-051e3a62f0d4"
      },
      "outputs": [],
      "source": [
        "reviewsDF.date.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA2gDdMq4iKB",
        "outputId": "5c39e010-2cad-4f6a-ac50-e08b468db06b"
      },
      "outputs": [],
      "source": [
        "reviewsDF.date.dt.year.value_counts() #to know the years of the available data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bw0_v203Gv0"
      },
      "outputs": [],
      "source": [
        "#subset the full dataset into yearly dataframes\n",
        "reviewsDF2011 = reviewsDF[reviewsDF.date.dt.year==2022]\n",
        "reviewsDF2015 = reviewsDF[reviewsDF.date.dt.year==2022]\n",
        "reviewsDF2016 = reviewsDF[reviewsDF.date.dt.year==2022]\n",
        "reviewsDF2017 = reviewsDF[reviewsDF.date.dt.year==2022]\n",
        "reviewsDF2018 = reviewsDF[reviewsDF.date.dt.year==2022]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ95mhLbL_Gn"
      },
      "source": [
        "Let's perform LSA to understand the topics for each year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw15LnPECHnP",
        "outputId": "336b8191-c6e2-48a2-e5eb-fe927e9d8649"
      },
      "outputs": [],
      "source": [
        "#2011\n",
        "reviewData = reviewsDF2011['text']\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', use_idf=True, smooth_idf=True)\n",
        "reviewData = reviewData.values\n",
        "document_term_matrix = tfidf_vectorizer.fit_transform(reviewData)\n",
        "#Let's consider the top 2 topics\n",
        "n_topics = 2\n",
        "lsa_model = TruncatedSVD(n_components=n_topics)\n",
        "lsa_topic_matrix = lsa_model.fit_transform(document_term_matrix)\n",
        "lsa_keys, lsa_categories, lsa_counts = getCategoriesCounts(lsa_topic_matrix)\n",
        "top_n_words_lsa = get_top_n_words(3, lsa_keys, document_term_matrix, tfidf_vectorizer)\n",
        "top_2011 = top_n_words_lsa\n",
        "for i in range(len(top_n_words_lsa)):\n",
        "    print(\"Topic {}: \".format(i+1), top_n_words_lsa[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvDpfDOCDauX",
        "outputId": "5f13dd33-0c51-4117-b255-3a022858b7d9"
      },
      "outputs": [],
      "source": [
        "#2015\n",
        "reviewData = reviewsDF2015['text']\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', use_idf=True, smooth_idf=True)\n",
        "reviewData = reviewData.values\n",
        "document_term_matrix = tfidf_vectorizer.fit_transform(reviewData)\n",
        "#Let's consider the top 14 topics\n",
        "n_topics = 10\n",
        "lsa_model = TruncatedSVD(n_components=n_topics)\n",
        "lsa_topic_matrix = lsa_model.fit_transform(document_term_matrix)\n",
        "lsa_keys, lsa_categories, lsa_counts = getCategoriesCounts(lsa_topic_matrix)\n",
        "top_n_words_lsa = get_top_n_words(3, lsa_keys, document_term_matrix, tfidf_vectorizer)\n",
        "top_2015 = top_n_words_lsa\n",
        "for i in range(len(top_n_words_lsa)):\n",
        "    print(\"Topic {}: \".format(i+1), top_n_words_lsa[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zL2mc7fHGKjL",
        "outputId": "bd2d1b3f-1764-4913-ce9c-1a03a7fac899"
      },
      "outputs": [],
      "source": [
        "#2016\n",
        "reviewData = reviewsDF2016['text']\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', use_idf=True, smooth_idf=True)\n",
        "reviewData = reviewData.values\n",
        "document_term_matrix = tfidf_vectorizer.fit_transform(reviewData)\n",
        "#Let's consider the top 15 topics\n",
        "n_topics = 10\n",
        "lsa_model = TruncatedSVD(n_components=n_topics)\n",
        "lsa_topic_matrix = lsa_model.fit_transform(document_term_matrix)\n",
        "lsa_keys, lsa_categories, lsa_counts = getCategoriesCounts(lsa_topic_matrix)\n",
        "top_n_words_lsa = get_top_n_words(3, lsa_keys, document_term_matrix, tfidf_vectorizer)\n",
        "top_2016 = top_n_words_lsa\n",
        "for i in range(len(top_n_words_lsa)):\n",
        "    print(\"Topic {}: \".format(i+1), top_n_words_lsa[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMgCZSbNGRBH",
        "outputId": "178c4b35-6803-467d-de8e-fb9e8247966e"
      },
      "outputs": [],
      "source": [
        "#2017\n",
        "reviewData = reviewsDF2017['text']\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', use_idf=True, smooth_idf=True)\n",
        "reviewData = reviewData.values\n",
        "document_term_matrix = tfidf_vectorizer.fit_transform(reviewData)\n",
        "#Let's consider the top 34 topics\n",
        "n_topics = 10\n",
        "lsa_model = TruncatedSVD(n_components=n_topics)\n",
        "lsa_topic_matrix = lsa_model.fit_transform(document_term_matrix)\n",
        "lsa_keys, lsa_categories, lsa_counts = getCategoriesCounts(lsa_topic_matrix)\n",
        "top_n_words_lsa = get_top_n_words(3, lsa_keys, document_term_matrix, tfidf_vectorizer)\n",
        "top_2017 = top_n_words_lsa\n",
        "for i in range(len(top_n_words_lsa)):\n",
        "    print(\"Topic {}: \".format(i+1), top_n_words_lsa[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdobhuX_GZwO",
        "outputId": "1512a73d-89bf-4d33-ac18-eaf811c23052"
      },
      "outputs": [],
      "source": [
        "#2018\n",
        "reviewData = reviewsDF2018['text']\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', use_idf=True, smooth_idf=True)\n",
        "reviewData = reviewData.values\n",
        "document_term_matrix = tfidf_vectorizer.fit_transform(reviewData)\n",
        "#Let's consider the top 12 topics\n",
        "n_topics = 12\n",
        "lsa_model = TruncatedSVD(n_components=n_topics)\n",
        "lsa_topic_matrix = lsa_model.fit_transform(document_term_matrix)\n",
        "lsa_keys, lsa_categories, lsa_counts = getCategoriesCounts(lsa_topic_matrix)\n",
        "top_n_words_lsa = get_top_n_words(3, lsa_keys, document_term_matrix, tfidf_vectorizer)\n",
        "top_2018 = top_n_words_lsa\n",
        "for i in range(len(top_n_words_lsa)):\n",
        "    print(\"Topic {}: \".format(i+1), top_n_words_lsa[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMIFYqC1MIXU"
      },
      "source": [
        "Visualizing the word cloud for each year to understand the most common words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "Ia-6uO5UGlfF",
        "outputId": "b62959fd-76d7-49f9-ad1d-b258ecbac416"
      },
      "outputs": [],
      "source": [
        "#2011\n",
        "wordcloud2011 = WordCloud(max_words = 200, max_font_size = 40, scale = 3, random_state = 42).generate(str(reviewsDF2011['text']))\n",
        "fig = plt.figure(1, figsize = (20, 20))\n",
        "plt.axis('off')\n",
        "plt.imshow(wordcloud2011)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "J8M20oIeHxHo",
        "outputId": "bd1eb55e-3f4e-4488-9600-c656c4afe3a1"
      },
      "outputs": [],
      "source": [
        "#2015\n",
        "wordcloud2015 = WordCloud(max_words = 200, max_font_size = 40, scale = 3, random_state = 42).generate(str(reviewsDF2015['text']))\n",
        "fig = plt.figure(1, figsize = (20, 20))\n",
        "plt.axis('off')\n",
        "plt.imshow(wordcloud2015)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "UUhJ5KiCH4vZ",
        "outputId": "ee42055d-8641-4c07-ddf0-a42a66c49a47"
      },
      "outputs": [],
      "source": [
        "#2016\n",
        "wordcloud2016 = WordCloud(max_words = 200, max_font_size = 40, scale = 3, random_state = 42).generate(str(reviewsDF2016['text']))\n",
        "fig = plt.figure(1, figsize = (20, 20))\n",
        "plt.axis('off')\n",
        "plt.imshow(wordcloud2016)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "iKygTk9xH6-s",
        "outputId": "d0ff6171-586f-4441-f572-c0d2697743c0"
      },
      "outputs": [],
      "source": [
        "#2017\n",
        "wordcloud2017 = WordCloud(max_words = 200, max_font_size = 40, scale = 3, random_state = 42).generate(str(reviewsDF2017['text']))\n",
        "fig = plt.figure(1, figsize = (20, 20))\n",
        "plt.axis('off')\n",
        "plt.imshow(wordcloud2017)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "tfwppCSWH-Lx",
        "outputId": "be001810-3425-4292-b3bf-cc10ac451ba4"
      },
      "outputs": [],
      "source": [
        "#2018\n",
        "wordcloud2018 = WordCloud(max_words = 200, max_font_size = 40, scale = 3, random_state = 42).generate(str(reviewsDF2018['text']))\n",
        "fig = plt.figure(1, figsize = (20, 20))\n",
        "plt.axis('off')\n",
        "plt.imshow(wordcloud2018)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X1KLqEG1IA5T",
        "outputId": "5bdc0c4f-a2c9-4895-cc2f-7c7ff415b2e3"
      },
      "outputs": [],
      "source": [
        "#Let's create a df with the top topics for all the years\n",
        "l1,l5,l6,l7,l8=len(top_2011),len(top_2015),len(top_2016),len(top_2017),len(top_2018)\n",
        "max_len = max(l1,l5,l6,l7,l8)\n",
        "\n",
        "if not max_len == l1:\n",
        "  top_2011.extend(['-']*(max_len-l1))\n",
        "if not max_len == l5:\n",
        "  top_2015.extend(['-']*(max_len-l5))\n",
        "if not max_len == l6:\n",
        "  top_2016.extend(['-']*(max_len-l6))\n",
        "if not max_len == l7:\n",
        "  top_2017.extend(['-']*(max_len-l7))\n",
        "if not max_len == l8:\n",
        "  top_2018.extend(['-']*(max_len-l8))\n",
        "\n",
        "topicsDF = pd.DataFrame({'2011':top_2011,'2015':top_2015,'2016':top_2016,'2017':top_2017,'2018':top_2018})\n",
        "topicsDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXpTUu_HmSoQ"
      },
      "source": [
        "Even though we have the top topics for each year, it is difficult to infer how the trend has changed over the years!  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "J7UlGBGNJMDS",
        "outputId": "13c587bd-e45c-4408-afaf-f75c20b7e0d9"
      },
      "outputs": [],
      "source": [
        "reviewsDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MA11zNmmhbV"
      },
      "source": [
        "As the number of reviews in 2011 is very less, lets plot the polarity for the remaining years in terms of time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "7qCjPVUmLNey",
        "outputId": "d4abc328-2f5e-4022-b7e1-8a05a663f90e"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=2, ncols=2,figsize=(15,10))\n",
        "#reviewsDF2011.plot.line(x='date',y='polarity',ax=axes[0,0])\n",
        "reviewsDF2015.plot.line(x='date',y='polarity',ax=axes[0,0],title='2015')\n",
        "reviewsDF2016.plot.line(x='date',y='polarity',ax=axes[0,1],title='2016')\n",
        "reviewsDF2017.plot.line(x='date',y='polarity',ax=axes[1,0],title='2017')\n",
        "reviewsDF2018.plot.line(x='date',y='polarity',ax=axes[1,1],title='2018')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "49CnNzWOsSff",
        "outputId": "4644d463-4fb4-4651-e351-dde8291c1ce5"
      },
      "outputs": [],
      "source": [
        "#Let's create a DF with the total number of positive and negative reviews detected for each year\n",
        "sentimentDF = pd.DataFrame(0,range(5),columns=['Year','pos','neg'])\n",
        "sentimentDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVGDM5pXsVYd"
      },
      "outputs": [],
      "source": [
        "sentimentDF.loc[0] = [2011,reviewsDF2011.Sentiment.value_counts()['pos'],reviewsDF2011.Sentiment.value_counts()['neg']]\n",
        "sentimentDF.loc[1] = [2015,reviewsDF2015.Sentiment.value_counts()['pos'],reviewsDF2015.Sentiment.value_counts()['neg']]\n",
        "sentimentDF.loc[2] = [2016,reviewsDF2016.Sentiment.value_counts()['pos'],reviewsDF2016.Sentiment.value_counts()['neg']]\n",
        "sentimentDF.loc[3] = [2017,reviewsDF2017.Sentiment.value_counts()['pos'],reviewsDF2017.Sentiment.value_counts()['neg']]\n",
        "sentimentDF.loc[4] = [2018,reviewsDF2018.Sentiment.value_counts()['pos'],reviewsDF2018.Sentiment.value_counts()['neg']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "TjykO1Essn0c",
        "outputId": "643566e6-6e0c-40b1-9f5b-e9b7726ba839"
      },
      "outputs": [],
      "source": [
        "sentimentDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "zoSD7FASuvdc",
        "outputId": "6528445a-90fa-4848-8523-dbb3321ffff3"
      },
      "outputs": [],
      "source": [
        "#Plot of positive vs negative reviews over the years\n",
        "sentimentDF.plot.line(x='Year')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRLqTC4cxj4N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjgFI85-KANT"
      },
      "source": [
        "# **LDA & Topic trend**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51uM_dilVblT"
      },
      "source": [
        "Now, even though the LSA provided the topics, let's analyze the topics using LDA in order to analyze the trend and to better visualize the topics "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "KG-cDWbJzWZF",
        "outputId": "b03253fa-fa50-4e36-83f8-d0c449ed32f5"
      },
      "outputs": [],
      "source": [
        "df = reviewsDF\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gliATW5AfR9"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "reviews = list(df['text'])\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "reviews = pd.Series(reviews).apply(lambda x: x.split())\n",
        "r1 = []\n",
        "for wrd in reviews:\n",
        "  doc = nlp(\" \".join(wrd))\n",
        "  r1.append([token.lemma_ for token in doc if token.pos_ in ['NOUN','ADJ']])\n",
        "\n",
        "reviewsR1 = r1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8sa6cDBAiBj"
      },
      "outputs": [],
      "source": [
        "#LDA\n",
        "dictionary = corpora.Dictionary(reviewsR1)\n",
        "doc_term_matrix = [dictionary.doc2bow(rev) for rev in reviewsR1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7XzF0zV01VC"
      },
      "outputs": [],
      "source": [
        "# Creating the object for LDA model using gensim library\n",
        "LDA = gensim.models.ldamodel.LdaModel\n",
        "# Build LDA model\n",
        "lda_model = LDA(corpus=doc_term_matrix, id2word=dictionary, num_topics=20, random_state=42,chunksize=1000, passes=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tlnUEXHV565",
        "outputId": "b6db34de-9efe-4225-bc49-cbc205262f6d"
      },
      "outputs": [],
      "source": [
        "#The top 20 topics that the LDA model has learned are\n",
        "lda_model.print_topics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUc3P_KN5uih",
        "outputId": "567fc52f-2e59-42ae-8483-514e1db14404"
      },
      "outputs": [],
      "source": [
        "#Just to check the correctness\n",
        "lda_model.get_document_topics(doc_term_matrix[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvAwv55Zmz4-"
      },
      "source": [
        "Using the **pyLDAvis** let's visualize the topics and relations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "id": "SwvGtXbw1ECd",
        "outputId": "249ba8fd-a076-4f75-ba35-1bc2aab66477"
      },
      "outputs": [],
      "source": [
        "#Visualizing using the pyLDAvis inbuilt viz\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, doc_term_matrix, dictionary)\n",
        "vis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-CmMJqP6GKB"
      },
      "outputs": [],
      "source": [
        "#Let's add a new column in the main df to get the topic number for each review\n",
        "doc_lda = lda_model[doc_term_matrix]\n",
        "max_topics = [max(sent, key=lambda x: x[1])[0] for sent in doc_lda]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoX9A8eQJgQy"
      },
      "outputs": [],
      "source": [
        "dftopic = df\n",
        "dftopic['topic'] = max_topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "id": "tZBpAIqrJlWR",
        "outputId": "f068f391-6425-4f7a-a2aa-054d75a01b52"
      },
      "outputs": [],
      "source": [
        "dftopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YlZ-SpQJ0rH",
        "outputId": "33fde364-3380-4be8-c309-7c0739945f70"
      },
      "outputs": [],
      "source": [
        "#the topics for the whole df\n",
        "dftopic.topic.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0BcTyh6J5vR"
      },
      "outputs": [],
      "source": [
        "#Topic numbers for the year 2011\n",
        "topic2011 = dftopic[dftopic.date.dt.year==2011]['topic'].value_counts().index.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0FoTHNCKn1N"
      },
      "outputs": [],
      "source": [
        "#Topic numbers for the year 2015\n",
        "topic2015 = dftopic[dftopic.date.dt.year==2015]['topic'].value_counts().index.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl5uvEdpKrYS"
      },
      "outputs": [],
      "source": [
        "#Topic numbers for the year 2016\n",
        "topic2016 = dftopic[dftopic.date.dt.year==2016]['topic'].value_counts().index.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b24jMdpxKtZp"
      },
      "outputs": [],
      "source": [
        "#Topic numbers for the year 2017\n",
        "topic2017 = dftopic[dftopic.date.dt.year==2017]['topic'].value_counts().index.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZoS5DzJKvBY"
      },
      "outputs": [],
      "source": [
        "#Topic numbers for the year 2018\n",
        "topic2018 = dftopic[dftopic.date.dt.year==2018]['topic'].value_counts().index.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IiZOKpxm9kU"
      },
      "source": [
        "The topics learned for each Year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBvmsa6zYwPU",
        "outputId": "51e43e43-7001-43c9-df55-89ede566acf5"
      },
      "outputs": [],
      "source": [
        "print(\"2011 - \",topic2011,\"\\n2015 - \",topic2015,\"\\n2016 - \",topic2016,\"\\n2017 - \",topic2017,\"\\n2018 - \",topic2018)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgVhpj0lnA9M"
      },
      "source": [
        "The list of all the topics learned with the LDA model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHpzs_YOZRwC",
        "outputId": "96a7dd1f-9907-4b5a-a7ed-549a82a15c86"
      },
      "outputs": [],
      "source": [
        "for i in range(len(lda_model.print_topics())):\n",
        "  print(\"Topic:%i\" %i ,\" - \", lda_model.print_topics()[i][1], '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CaEg_NzYScf"
      },
      "source": [
        "We can see from above that:\n",
        "\n",
        "In 2011: There are only 2 topics - Topic #15 and Topic#0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9XPe2dOzKwIZ",
        "outputId": "39bb79c7-6376-4f27-fd79-fe4cc7dbe711"
      },
      "outputs": [],
      "source": [
        "lda_model.print_topics()[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkUsLsbwYNdE",
        "outputId": "7f108634-67cf-48c1-b41a-4f63b8291859"
      },
      "outputs": [],
      "source": [
        "list(set(topic2011).intersection(topic2015))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2EjCe9NbnXC"
      },
      "source": [
        "From 2011 to 2015 there are two common topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7kFCeMpaZPX",
        "outputId": "d6c90bee-6008-438b-97db-aaa7d873ec15"
      },
      "outputs": [],
      "source": [
        "list(set(topic2015).intersection(topic2016))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqL3_oFqbO1E"
      },
      "source": [
        "We can see that from 2015 to 2016 Topic #0 and #15 have been continued, and many more topics have been added"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUPcIyWAa5w4",
        "outputId": "ef149000-201c-4dec-a856-46e7001a6651"
      },
      "outputs": [],
      "source": [
        "list(set(topic2016).intersection(topic2017))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0UDYYfObrRO"
      },
      "source": [
        "From 2016 to 2017, most of the topics are still common and some more have been added"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbEfASXbbaMB",
        "outputId": "5456a4e7-83d2-4d32-fb42-05935ec2ce4b"
      },
      "outputs": [],
      "source": [
        "list(set(topic2017).intersection(topic2018))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPtIdvRZb3e2"
      },
      "source": [
        "Again from 2017 to 2018, most of the topics have still been common "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrFlu7GGkOD4"
      },
      "outputs": [],
      "source": [
        "for i in range(20):\n",
        "  print(\"Topic:%i\" %i )\n",
        "  print(df[df.topic == i]['rating'].value_counts().index[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKt0ome-kQor"
      },
      "source": [
        "we can see that almost all the topics have the highest number of negative reviews except Topic #6 and #3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-DTw3ZocE_a"
      },
      "source": [
        "From the above learned topics, let's consider one of the most common topic #10 that has been talked about since 2015, which indicates it's one of the most important things people are talking about "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sAhYs-vchz8",
        "outputId": "bb08f6fe-4b8e-48ed-8079-51bfbfc2d149"
      },
      "outputs": [],
      "source": [
        "#Let's see some reviews with the topic #10\n",
        "list(df[df.topic == 10]['text'][:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLQpQ9xLcsQ_",
        "outputId": "7ad3d48f-36fd-4f3f-91dd-e6be96354254"
      },
      "outputs": [],
      "source": [
        "df[df.topic == 10]['rating'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyDJMI8kdNfO"
      },
      "source": [
        "We can see from above that most of the reviews are negative, and almost more thatn 75% of the reviews have a 1-star rating. So, we can confirm that this is one of the most important topic people have been talking about over the years.\n",
        "\n",
        "Similarly we can analyze the rest of the topics depending on the requirement, and how the service wants to be improved, for example if they want to improve the Application, they can see the topic most related to \"app\" and then do the same analysis as above. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8mljWTqfHKg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "OkraFinal.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
